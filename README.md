# Atlas-hackathon
Behavior Analysis on birds' sounds

# Problem Statement 
Nature doesnâ€™t just look different when it's sick, it sounds different. 
There exist multiple methods to detect forest health- but all these are all too reliant on visuals, and worst of all, they conclude too late. Methods like satellite imaging consist of too much latency and can show you only the past, while audio can show you the present.
This is why we choose sound, we choose to listen because a forest can look green but be "acoustically dead", which signals real, future decline.
To understand how our ai thinks, we need to clear out some of the basics first

References: 
- https://keras.io/api/applications/efficientnet_v2/ - Model used for the transfer learning
- https://xeno-canto.org - Bird calls' databse
- https://ebird.org/home - Data about every bird ever
- https://github.com/stateofindiasbirds/soib_2023 - Reference for India's birds (currently trained for only Mahrashtra)
